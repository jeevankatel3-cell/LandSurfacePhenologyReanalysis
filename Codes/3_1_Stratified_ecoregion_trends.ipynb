{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b57e272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trend analysis for each ecoregion of Nepal based on different SUs\n",
    "#Input: 1. Trend Raster (all fitted and significant only)\n",
    "#        2. DEM Raster (elevation, slope (degrees), aspect (degrees))\n",
    "\n",
    "# Workflow steps : 0. SUs stratified by ecoregions > elevation > aspect > slope\n",
    "#                 1. no of trend fitted pixels for each SU (>10 for valid)\n",
    "#                 2. percentage of significant pixels for each SU (> %5 for valid)\n",
    "#                 3. no of pixels with postive trend and negative trend\n",
    "#                 4. Trend Assymetry Ratio: #n/#p (> 2 or <0.5 for valid)\n",
    "#                 5. SUs that pass all criteria \n",
    "#                 6. Ecoregion trend (areal% and slope in both direction) derived from valid SUs\n",
    "\n",
    "#starting with a simple code only considering sos  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c257ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECO_ID     ECO_NAME\n",
    "# 81003     Eastern Himalayan alpine shrub and meadows\n",
    "# 40115     Himalayan subtropical broadleaf forests\n",
    "# 40301     Himalayan subtropical pine forests\n",
    "# 40403     Western Himalayan broadleaf forests\n",
    "# -9999     Rock and Ice\n",
    "# 40401     Eastern Himalayan broadleaf forests\n",
    "# 40166     Upper Gangetic Plains moist deciduous forests - assign value null at last for all variables\n",
    "# 81021     Western Himalayan alpine shrub and Meadows\n",
    "# 40701     Terai-Duar savanna and grasslands\n",
    "# 40501     Eastern Himalayan subalpine conifer forests\n",
    "# 40502     Western Himalayan subalpine conifer forests\n",
    "# 40120     Lower Gangetic Plains moist deciduous forests - assign value null at last for all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26e64cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries and data\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr \n",
    "import rasterio as rio  \n",
    "import rioxarray as rxr \n",
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "ecoregion_rxr = rxr.open_rasterio(r\"..\\Data\\Ecoregion_raster\\ecoregions_raster.tif\")\n",
    "\n",
    "elev_rxr = rxr.open_rasterio(r\"..\\Data\\DEM_Rasters\\elevation.tif\")\n",
    "aspect_rxr = rxr.open_rasterio(r\"..\\Data\\DEM_Rasters\\aspect.tif\")\n",
    "slope_rxr = rxr.open_rasterio(r\"..\\Data\\DEM_Rasters\\slope.tif\")\n",
    "\n",
    "roi_gdf = gpd.read_file(r\"../Data/roi_nepal/nepal_actual_roi.shp\")\n",
    "roi = roi_gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "output_dir = r\"../Data/Processed/Ecoregion_trends/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "711d0bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess dem rasters, actual values to classes\n",
    "# divide elevation, slope, aspect into classes\n",
    "\n",
    "# Elevation classes: <1000: 1, 1000-2000: 2, 2000-3000: 3, 3000-4000: 4, >4000: 5\n",
    "elev_class = xr.where(elev_rxr < 1000, 1, \n",
    "                      xr.where(elev_rxr < 2000, 2,\n",
    "                               xr.where(elev_rxr < 3000, 3,\n",
    "                                        xr.where(elev_rxr < 4000, 4, 5))))\n",
    "\n",
    "# Slope classes: 0-2: 1, 2-15: 2, 15-30: 3, >30: 4              Reference: FAO(2006)\n",
    "slope_class = xr.where(slope_rxr < 2, 1,\n",
    "                       xr.where(slope_rxr < 15, 2,\n",
    "                                xr.where(slope_rxr < 30, 3, 4)))\n",
    "\n",
    "# Aspect classes: Northern (270-360, 0-90): 1, Southern (90-270): 2\n",
    "aspect_class = xr.where((aspect_rxr >= 0) & (aspect_rxr <= 90), 1,\n",
    "                        xr.where((aspect_rxr >= 270) & (aspect_rxr <= 360), 1,\n",
    "                                 xr.where((aspect_rxr > 90) & (aspect_rxr < 270), 2, np.nan)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9625b7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A S U S\\AppData\\Local\\Temp\\ipykernel_15692\\3232685818.py:34: FutureWarning: In a future version of xarray the default value for compat will change from compat='no_conflicts' to compat='override'. This is likely to lead to different results when combining overlapping variables with the same name. To opt in to new defaults and get rid of these warnings now use `set_options(use_new_combine_kwarg_defaults=True) or set compat explicitly.\n",
      "  stacked_xr = xr.merge(aligned_rasters)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Statistics for SOS\n",
      "==================================================\n",
      "total_pixels: 2565421\n",
      "total trend fitted pixels: 2044237\n",
      "total significant pixels: 159563\n",
      "trend fitted / total  %: 79.68\n",
      "significant / trend fitted  %: 7.81\n",
      "significant / total  %: 6.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A S U S\\AppData\\Local\\Temp\\ipykernel_15692\\3232685818.py:34: FutureWarning: In a future version of xarray the default value for compat will change from compat='no_conflicts' to compat='override'. This is likely to lead to different results when combining overlapping variables with the same name. To opt in to new defaults and get rid of these warnings now use `set_options(use_new_combine_kwarg_defaults=True) or set compat explicitly.\n",
      "  stacked_xr = xr.merge(aligned_rasters)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Statistics for EOS\n",
      "==================================================\n",
      "total_pixels: 2565421\n",
      "total trend fitted pixels: 2045288\n",
      "total significant pixels: 154988\n",
      "trend fitted / total  %: 79.73\n",
      "significant / trend fitted  %: 7.58\n",
      "significant / total  %: 6.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A S U S\\AppData\\Local\\Temp\\ipykernel_15692\\3232685818.py:34: FutureWarning: In a future version of xarray the default value for compat will change from compat='no_conflicts' to compat='override'. This is likely to lead to different results when combining overlapping variables with the same name. To opt in to new defaults and get rid of these warnings now use `set_options(use_new_combine_kwarg_defaults=True) or set compat explicitly.\n",
      "  stacked_xr = xr.merge(aligned_rasters)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Statistics for LOS\n",
      "==================================================\n",
      "total_pixels: 2565421\n",
      "total trend fitted pixels: 2045288\n",
      "total significant pixels: 191144\n",
      "trend fitted / total  %: 79.73\n",
      "significant / trend fitted  %: 9.35\n",
      "significant / total  %: 7.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A S U S\\AppData\\Local\\Temp\\ipykernel_15692\\3232685818.py:34: FutureWarning: In a future version of xarray the default value for compat will change from compat='no_conflicts' to compat='override'. This is likely to lead to different results when combining overlapping variables with the same name. To opt in to new defaults and get rid of these warnings now use `set_options(use_new_combine_kwarg_defaults=True) or set compat explicitly.\n",
      "  stacked_xr = xr.merge(aligned_rasters)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Statistics for POS\n",
      "==================================================\n",
      "total_pixels: 2565421\n",
      "total trend fitted pixels: 2045288\n",
      "total significant pixels: 513054\n",
      "trend fitted / total  %: 79.73\n",
      "significant / trend fitted  %: 25.08\n",
      "significant / total  %: 20.00\n"
     ]
    }
   ],
   "source": [
    "lsp_metrics = ['sos', 'eos', 'los', 'pos']\n",
    "\n",
    "# Initialize list to store pixel statistics for each metric\n",
    "pixel_stats_list = []\n",
    "\n",
    "for metric in lsp_metrics:\n",
    "    trend_rxr = rxr.open_rasterio(r\"..\\Data\\Trend_Rasters\\mod_\"+metric+\"_mk_raw.tif\")\n",
    "    sig_trend_rxr = rxr.open_rasterio(r\"..\\Data\\Trend_Rasters\\mod_\"+metric+\"_mk_significant.tif\")\n",
    "    final_outdir = os.path.join(output_dir, f\"{metric}\")\n",
    "    os.makedirs(final_outdir, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    #stack rasters to create a pd dataframe\n",
    "    ref = sig_trend_rxr.rio.clip(roi.geometry, roi.crs, drop=True)\n",
    "\n",
    "    raster_dict = {\n",
    "        \"ecoregion\": ecoregion_rxr,\n",
    "        \"elevation\": elev_class,\n",
    "        \"slope\": slope_class,\n",
    "        \"aspect\": aspect_class,\n",
    "        \"trend\": trend_rxr,\n",
    "        \"sig_trend\": sig_trend_rxr\n",
    "    }\n",
    "\n",
    "    aligned_rasters = []\n",
    "\n",
    "    for name, raster in raster_dict.items():\n",
    "        raster = raster.rio.write_crs(\"EPSG: 4326\")\n",
    "        reproj = raster.rio.reproject_match(ref)\n",
    "        reproj.name = name\n",
    "        reproj = reproj.squeeze('band', drop = True)\n",
    "        aligned_rasters.append(reproj)\n",
    "\n",
    "    stacked_xr = xr.merge(aligned_rasters)\n",
    "    stacked_df = stacked_xr.to_dataframe().reset_index()\n",
    "    \n",
    "    #filter for select ecoregions\n",
    "    select_ecoregions = [81003, 40115, 40301, 40403, 40401, 81021, 40701, 40501, 40502]\n",
    "    stacked_df = stacked_df[stacked_df['ecoregion'].isin(select_ecoregions)]\n",
    "    stacked_df1 = stacked_df[~((stacked_df['trend'] == -999) )]\n",
    "    stacked_df2 = stacked_df[~((stacked_df['trend'] == -999) | (stacked_df['sig_trend'] == -999))]\n",
    "\n",
    "    # Calculate statistics\n",
    "    total_pixels = stacked_df.shape[0]\n",
    "    total_trend_fitted = stacked_df1.shape[0]\n",
    "    total_significant = stacked_df2.shape[0]\n",
    "    \n",
    "    trend_fitted_pct = (total_trend_fitted / total_pixels) * 100\n",
    "    sig_from_fitted_pct = (total_significant / total_trend_fitted) * 100\n",
    "    sig_from_total_pct = (total_significant / total_pixels) * 100\n",
    "    \n",
    "    # Print statistics (original behavior)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Statistics for {metric.upper()}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(\"total_pixels:\", total_pixels)\n",
    "    print(\"total trend fitted pixels:\", total_trend_fitted)\n",
    "    print(\"total significant pixels:\", total_significant)\n",
    "    print(f\"trend fitted / total  %: {trend_fitted_pct:.2f}\")\n",
    "    print(f\"significant / trend fitted  %: {sig_from_fitted_pct:.2f}\")\n",
    "    print(f\"significant / total  %: {sig_from_total_pct:.2f}\")\n",
    "    \n",
    "    # Store statistics for CSV\n",
    "    pixel_stats_list.append({\n",
    "        'lsp_metric': metric,\n",
    "        'total_pixels': total_pixels,\n",
    "        'trend_fitted_pixels': total_trend_fitted,\n",
    "        'significant_pixels': total_significant,\n",
    "        'trend_fitted_pct': round(trend_fitted_pct, 2),\n",
    "        'sig_from_fitted_pct': round(sig_from_fitted_pct, 2),\n",
    "        'sig_from_total_pct': round(sig_from_total_pct, 2)\n",
    "    })\n",
    "\n",
    "    stacked_df['trend'] = stacked_df['trend'].fillna(-999)\n",
    "\n",
    "    su_stats = stacked_df.groupby(['ecoregion', 'elevation', 'slope', 'aspect']).agg(\n",
    "        \n",
    "        # 1. Trend Pixels\n",
    "        n_trend_unfitted_count=('trend', lambda x: (x == -999).sum()),\n",
    "        n_trend_fitted_count=('trend', lambda x: (x != -999).sum()),\n",
    "        \n",
    "        # 2. Significance Pixels\n",
    "        n_insig_trend_count=('sig_trend', lambda x: (x == -999).sum()),\n",
    "        n_sig_trend_count=('sig_trend', lambda x: ((x != -999) & (~x.isna())).sum()),\n",
    "        \n",
    "        # Positive and negative trends (for significant pixels only)\n",
    "        positive_sig_trend_count=('sig_trend', lambda x: ((x > 0) & (x != -999)).sum()),\n",
    "        negative_sig_trend_count=('sig_trend', lambda x: ((x < 0) & (x != -999)).sum()),\n",
    "        \n",
    "        # Mean values (excluding -999 and NaN)\n",
    "        positive_sig_trend_mean=('sig_trend', lambda x: x[(x > 0) & (x != -999)].mean() if len(x[(x > 0) & (x != -999)]) > 0 else np.nan),\n",
    "        negative_sig_trend_mean=('sig_trend', lambda x: x[(x < 0) & (x != -999)].mean() if len(x[(x < 0) & (x != -999)]) > 0 else np.nan),\n",
    "        all_sig_trend_mean=('sig_trend', lambda x: x[(x != -999) & (~x.isna())].mean())\n",
    "    ).reset_index()\n",
    "\n",
    "    # Add derived metrics based on your workflow\n",
    "    su_stats['percent_sig_pixels'] = (su_stats['n_sig_trend_count'] / su_stats['n_trend_fitted_count']) * 100\n",
    "    su_stats['trend_asymmetry_ratio'] = su_stats['positive_sig_trend_count'] / su_stats['negative_sig_trend_count']\n",
    "\n",
    "\n",
    "    #based on the set criteria we divide SUs into either 'valid' or 'invalid' category in lsp_change\n",
    "    su_stats['lsp_change'] = np.where(\n",
    "        (su_stats['n_trend_fitted_count'] > 10) &  # At least 10 fitted pixels\n",
    "        (su_stats['percent_sig_pixels'] > 5) &      # At least 5% significant\n",
    "        ((su_stats['trend_asymmetry_ratio'] > 2) | (su_stats['trend_asymmetry_ratio'] < 0.5)),  # Strong asymmetry\n",
    "        1,                  #means yes or valid\n",
    "        0                   #means no or invalid\n",
    "    )\n",
    "\n",
    "    su_stats.to_csv(os.path.join(final_outdir, \"All_SU_Stats_\"+metric+\".csv\"), index=False)\n",
    "\n",
    "    #from this step we drop all SUs with invalid lsp_change\n",
    "    # all % are calculated based on the ecoregions area (total pixels of that ecoregions)\n",
    "\n",
    "    ecr_count = su_stats.groupby('ecoregion')[['n_trend_fitted_count', 'n_trend_unfitted_count']].sum().reset_index()\n",
    "    ecr_count['total_pixels'] = ecr_count['n_trend_fitted_count'] + ecr_count['n_trend_unfitted_count']\n",
    "    ecr_count = ecr_count.drop(columns=['n_trend_fitted_count', 'n_trend_unfitted_count'])\n",
    "\n",
    "    su_filtered = (su_stats[su_stats['lsp_change'] == 1]).drop(columns=['lsp_change'])\n",
    "    ecr_stats = su_filtered.groupby('ecoregion').agg(\n",
    "        n_trend_fitted_count = ('n_trend_fitted_count', 'sum'),\n",
    "        n_sig_trend_count=('n_sig_trend_count', 'sum'),\n",
    "        positive_sig_trend_count=('positive_sig_trend_count', 'sum'),\n",
    "        negative_sig_trend_count=('negative_sig_trend_count', 'sum'),\n",
    "        positive_sig_trend_mean=('positive_sig_trend_mean', 'mean'),\n",
    "        negative_sig_trend_mean=('negative_sig_trend_mean', 'mean'),\n",
    "        all_sig_trend_mean=('all_sig_trend_mean', 'mean')\n",
    "    )\n",
    "\n",
    "    ecr_stats = pd.merge(ecr_stats, ecr_count, on='ecoregion', how = 'inner')    \n",
    "\n",
    "    ecr_stats['percent_trend_fit_px'] = (ecr_stats['n_trend_fitted_count'] / ecr_stats['total_pixels']) * 100\n",
    "    ecr_stats['percent_significant_valid_px'] = (ecr_stats['n_sig_trend_count'] / ecr_stats['n_trend_fitted_count']) * 100\n",
    "    ecr_stats['percent_positive_valid_px'] = (ecr_stats['positive_sig_trend_count'] / ecr_stats['n_trend_fitted_count']) * 100\n",
    "    ecr_stats['percent_negative_valid_px'] = (ecr_stats['negative_sig_trend_count'] / ecr_stats['n_trend_fitted_count']) * 100\n",
    "    ecr_stats['trend_asymmetry_ratio'] = ecr_stats['positive_sig_trend_count'] / ecr_stats['negative_sig_trend_count']\n",
    "\n",
    "    #calculate net area % and net trend mean for ecoregions with notably asymmetric trend\n",
    "    ecr_stats['net_area_percent'] = np.where(ecr_stats['trend_asymmetry_ratio'] > 2,\n",
    "        ecr_stats['percent_positive_valid_px'] - ecr_stats['percent_negative_valid_px'],\n",
    "        np.where(ecr_stats['trend_asymmetry_ratio'] < 0.5,\n",
    "            ecr_stats['percent_positive_valid_px'] - ecr_stats['percent_negative_valid_px'],\n",
    "            0\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    ecr_stats = (ecr_stats[['ecoregion',\n",
    "        'percent_positive_valid_px',\n",
    "        'percent_negative_valid_px',\n",
    "        'positive_sig_trend_mean',\n",
    "        'negative_sig_trend_mean',\n",
    "        'trend_asymmetry_ratio',\n",
    "        'net_area_percent']])\n",
    "    ecr_stats = ecr_stats.round(2)\n",
    "    ecr_stats.to_csv(os.path.join(final_outdir, \"ecoregion_stats.csv\"), index=False)\n",
    "\n",
    "# Convert to DataFrame and save as CSV\n",
    "pixel_stats_df = pd.DataFrame(pixel_stats_list)\n",
    "pixel_stats_df.to_csv(os.path.join(output_dir, \"pixel_statistics_summary.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d5052a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Topographic Drivers for SOS\n",
      "==================================================\n",
      "Criteria: p < 0.05 AND |r| > 0.1\n",
      "\n",
      "Interpretation:\n",
      "  + value = Higher class/North aspect → more positive trends\n",
      "  - value = Higher class/South aspect → more negative trends\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsp_metric</th>\n",
       "      <th>ecoregion</th>\n",
       "      <th>elev_r</th>\n",
       "      <th>slope_r</th>\n",
       "      <th>aspect_r</th>\n",
       "      <th>elev_p</th>\n",
       "      <th>slope_p</th>\n",
       "      <th>aspect_p</th>\n",
       "      <th>is_elev_driver</th>\n",
       "      <th>is_slope_driver</th>\n",
       "      <th>is_aspect_driver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sos</td>\n",
       "      <td>40115</td>\n",
       "      <td>-0.722</td>\n",
       "      <td>-0.771</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sos</td>\n",
       "      <td>40301</td>\n",
       "      <td>0.193</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4903</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sos</td>\n",
       "      <td>40401</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.9224</td>\n",
       "      <td>0.8711</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sos</td>\n",
       "      <td>40403</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.3717</td>\n",
       "      <td>0.7549</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sos</td>\n",
       "      <td>40501</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2344</td>\n",
       "      <td>0.5868</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sos</td>\n",
       "      <td>40502</td>\n",
       "      <td>0.208</td>\n",
       "      <td>-0.535</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.5915</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sos</td>\n",
       "      <td>81003</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4679</td>\n",
       "      <td>0.3809</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lsp_metric  ecoregion  elev_r  slope_r  aspect_r  elev_p  slope_p  aspect_p  \\\n",
       "0        sos      40115  -0.722   -0.771     0.000  0.0671   0.0424    1.0000   \n",
       "1        sos      40301   0.193   -0.061     0.000  0.4903   0.8294    1.0000   \n",
       "2        sos      40401   0.669    0.020    -0.037  0.0002   0.9224    0.8711   \n",
       "3        sos      40403   0.339    0.122     0.000  0.3717   0.7549    1.0000   \n",
       "4        sos      40501   0.865    0.305     0.142  0.0000   0.2344    0.5868   \n",
       "5        sos      40502   0.208   -0.535     0.000  0.5915   0.1381    1.0000   \n",
       "6        sos      81003   0.372   -0.441     0.000  0.4679   0.3809    1.0000   \n",
       "\n",
       "  is_elev_driver is_slope_driver is_aspect_driver  \n",
       "0             NO             YES               NO  \n",
       "1             NO              NO               NO  \n",
       "2            YES              NO               NO  \n",
       "3             NO              NO               NO  \n",
       "4            YES              NO               NO  \n",
       "5             NO              NO               NO  \n",
       "6             NO              NO               NO  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Topographic Drivers for EOS\n",
      "==================================================\n",
      "Criteria: p < 0.05 AND |r| > 0.1\n",
      "\n",
      "Interpretation:\n",
      "  + value = Higher class/North aspect → more positive trends\n",
      "  - value = Higher class/South aspect → more negative trends\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsp_metric</th>\n",
       "      <th>ecoregion</th>\n",
       "      <th>elev_r</th>\n",
       "      <th>slope_r</th>\n",
       "      <th>aspect_r</th>\n",
       "      <th>elev_p</th>\n",
       "      <th>slope_p</th>\n",
       "      <th>aspect_p</th>\n",
       "      <th>is_elev_driver</th>\n",
       "      <th>is_slope_driver</th>\n",
       "      <th>is_aspect_driver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eos</td>\n",
       "      <td>40301</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.2721</td>\n",
       "      <td>0.0426</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eos</td>\n",
       "      <td>40401</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.480</td>\n",
       "      <td>0.5085</td>\n",
       "      <td>0.6739</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eos</td>\n",
       "      <td>40403</td>\n",
       "      <td>0.359</td>\n",
       "      <td>-0.707</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.5528</td>\n",
       "      <td>0.1817</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eos</td>\n",
       "      <td>40501</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eos</td>\n",
       "      <td>40502</td>\n",
       "      <td>0.881</td>\n",
       "      <td>-0.431</td>\n",
       "      <td>-0.345</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.2195</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eos</td>\n",
       "      <td>81003</td>\n",
       "      <td>-0.822</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.5294</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eos</td>\n",
       "      <td>81021</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.569</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.8150</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lsp_metric  ecoregion  elev_r  slope_r  aspect_r  elev_p  slope_p  aspect_p  \\\n",
       "0        eos      40301   0.329    0.569     0.000  0.2721   0.0426    1.0000   \n",
       "1        eos      40401   0.157   -0.100    -0.480  0.5085   0.6739    0.0347   \n",
       "2        eos      40403   0.359   -0.707     0.000  0.5528   0.1817    1.0000   \n",
       "3        eos      40501  -0.334    0.453     0.000  0.2885   0.1397    1.0000   \n",
       "4        eos      40502   0.881   -0.431    -0.345  0.0000   0.1241    0.2195   \n",
       "5        eos      81003  -0.822    0.243     0.000  0.0066   0.5294    1.0000   \n",
       "6        eos      81021  -0.064   -0.569     0.499  0.8150   0.0214    0.0519   \n",
       "\n",
       "  is_elev_driver is_slope_driver is_aspect_driver  \n",
       "0             NO             YES               NO  \n",
       "1             NO              NO              YES  \n",
       "2             NO              NO               NO  \n",
       "3             NO              NO               NO  \n",
       "4            YES              NO               NO  \n",
       "5            YES              NO               NO  \n",
       "6             NO             YES               NO  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Topographic Drivers for LOS\n",
      "==================================================\n",
      "Criteria: p < 0.05 AND |r| > 0.1\n",
      "\n",
      "Interpretation:\n",
      "  + value = Higher class/North aspect → more positive trends\n",
      "  - value = Higher class/South aspect → more negative trends\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsp_metric</th>\n",
       "      <th>ecoregion</th>\n",
       "      <th>elev_r</th>\n",
       "      <th>slope_r</th>\n",
       "      <th>aspect_r</th>\n",
       "      <th>elev_p</th>\n",
       "      <th>slope_p</th>\n",
       "      <th>aspect_p</th>\n",
       "      <th>is_elev_driver</th>\n",
       "      <th>is_slope_driver</th>\n",
       "      <th>is_aspect_driver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>los</td>\n",
       "      <td>40115</td>\n",
       "      <td>-0.365</td>\n",
       "      <td>-0.477</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.3339</td>\n",
       "      <td>0.1946</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>los</td>\n",
       "      <td>40301</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>0.1341</td>\n",
       "      <td>0.2656</td>\n",
       "      <td>0.1774</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>los</td>\n",
       "      <td>40401</td>\n",
       "      <td>-0.698</td>\n",
       "      <td>0.095</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.6997</td>\n",
       "      <td>0.3469</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>los</td>\n",
       "      <td>40403</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.591</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.7489</td>\n",
       "      <td>0.0719</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>los</td>\n",
       "      <td>40501</td>\n",
       "      <td>-0.827</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4065</td>\n",
       "      <td>0.3117</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>los</td>\n",
       "      <td>81003</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8518</td>\n",
       "      <td>0.2774</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>los</td>\n",
       "      <td>81021</td>\n",
       "      <td>-0.775</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.6871</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lsp_metric  ecoregion  elev_r  slope_r  aspect_r  elev_p  slope_p  aspect_p  \\\n",
       "0        los      40115  -0.365   -0.477     0.000  0.3339   0.1946    1.0000   \n",
       "1        los      40301  -0.356   -0.269    -0.322  0.1341   0.2656    0.1774   \n",
       "2        los      40401  -0.698    0.095    -0.225  0.0009   0.6997    0.3469   \n",
       "3        los      40403  -0.116   -0.591     0.000  0.7489   0.0719    1.0000   \n",
       "4        los      40501  -0.827    0.215     0.257  0.0000   0.4065    0.3117   \n",
       "5        los      81003  -0.064    0.360     0.000  0.8518   0.2774    1.0000   \n",
       "6        los      81021  -0.775    0.170     0.000  0.0239   0.6871    1.0000   \n",
       "\n",
       "  is_elev_driver is_slope_driver is_aspect_driver  \n",
       "0             NO              NO               NO  \n",
       "1             NO              NO               NO  \n",
       "2            YES              NO               NO  \n",
       "3             NO              NO               NO  \n",
       "4            YES              NO               NO  \n",
       "5             NO              NO               NO  \n",
       "6            YES              NO               NO  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Topographic Drivers for POS\n",
      "==================================================\n",
      "Criteria: p < 0.05 AND |r| > 0.1\n",
      "\n",
      "Interpretation:\n",
      "  + value = Higher class/North aspect → more positive trends\n",
      "  - value = Higher class/South aspect → more negative trends\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A S U S\\AppData\\Local\\Temp\\ipykernel_15692\\1844569235.py:33: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho_elev, p_elev = spearmanr(group['elevation'], group['asymmetry_index'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsp_metric</th>\n",
       "      <th>ecoregion</th>\n",
       "      <th>elev_r</th>\n",
       "      <th>slope_r</th>\n",
       "      <th>aspect_r</th>\n",
       "      <th>elev_p</th>\n",
       "      <th>slope_p</th>\n",
       "      <th>aspect_p</th>\n",
       "      <th>is_elev_driver</th>\n",
       "      <th>is_slope_driver</th>\n",
       "      <th>is_aspect_driver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>40115</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.752</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.9163</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>40301</td>\n",
       "      <td>-0.330</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.8542</td>\n",
       "      <td>0.9385</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>40401</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.324</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.6734</td>\n",
       "      <td>0.0615</td>\n",
       "      <td>0.2758</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>40403</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.3633</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>40501</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.081</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>0.6394</td>\n",
       "      <td>0.7013</td>\n",
       "      <td>0.1204</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pos</td>\n",
       "      <td>40502</td>\n",
       "      <td>-0.918</td>\n",
       "      <td>0.324</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.3847</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pos</td>\n",
       "      <td>40701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.837</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pos</td>\n",
       "      <td>81003</td>\n",
       "      <td>0.692</td>\n",
       "      <td>-0.394</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.1057</td>\n",
       "      <td>0.6582</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pos</td>\n",
       "      <td>81021</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.074</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.7235</td>\n",
       "      <td>0.7772</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lsp_metric  ecoregion  elev_r  slope_r  aspect_r  elev_p  slope_p  aspect_p  \\\n",
       "0        pos      40115   0.000   -0.752    -0.039  1.0000   0.0008    0.9163   \n",
       "1        pos      40301  -0.330   -0.038     0.020  0.1002   0.8542    0.9385   \n",
       "2        pos      40401   0.075    0.324    -0.189  0.6734   0.0615    0.2758   \n",
       "3        pos      40403   0.470    0.186     0.136  0.0154   0.3633    0.5050   \n",
       "4        pos      40501   0.099    0.081    -0.315  0.6394   0.7013    0.1204   \n",
       "5        pos      40502  -0.918    0.324    -0.203  0.0000   0.1628    0.3847   \n",
       "6        pos      40701     NaN   -0.837     0.000     NaN   0.0378    1.0000   \n",
       "7        pos      81003   0.692   -0.394     0.114  0.0015   0.1057    0.6582   \n",
       "8        pos      81021   0.093    0.074    -0.082  0.7235   0.7772    0.7727   \n",
       "\n",
       "  is_elev_driver is_slope_driver is_aspect_driver  \n",
       "0             NO             YES               NO  \n",
       "1             NO              NO               NO  \n",
       "2             NO              NO               NO  \n",
       "3            YES              NO               NO  \n",
       "4             NO              NO               NO  \n",
       "5            YES              NO               NO  \n",
       "6             NO             YES               NO  \n",
       "7            YES              NO               NO  \n",
       "8             NO              NO               NO  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Topographic Driver Analysis - Which factors control LSP change direction?\n",
    "# For each ecoregion and metric, test if Elevation, Slope, or Aspect significantly influence trend asymmetry\n",
    "\n",
    "from scipy.stats import spearmanr, mannwhitneyu\n",
    "\n",
    "# Initialize list to store driver results for all metrics\n",
    "all_driver_results = []\n",
    "\n",
    "for metric in lsp_metrics:\n",
    "    final_outdir = os.path.join(output_dir, f\"{metric}\")\n",
    "    \n",
    "    # Load the SU stats for this metric\n",
    "    su_stats = pd.read_csv(os.path.join(final_outdir, \"All_SU_Stats_\"+metric+\".csv\"))\n",
    "    \n",
    "    # Step 1: Create normalized asymmetry index (avoids division by zero)\n",
    "    # Range: -1 (all positive trends) to +1 (all negative trends)\n",
    "    su_stats['asymmetry_index'] = (\n",
    "        (su_stats['positive_sig_trend_count'] - su_stats['negative_sig_trend_count']) /\n",
    "        (su_stats['positive_sig_trend_count'] + su_stats['negative_sig_trend_count'])\n",
    "    )\n",
    "    \n",
    "    # Step 2: Filter for valid SUs only\n",
    "    valid_sus = su_stats[su_stats['lsp_change'] == 1].dropna(subset=['asymmetry_index'])\n",
    "    \n",
    "    # Step 3: Test each ecoregion\n",
    "    driver_results = []\n",
    "    \n",
    "    for eco_id, group in valid_sus.groupby('ecoregion'):\n",
    "        if len(group) < 5:  # Skip if too few SUs\n",
    "            continue\n",
    "        \n",
    "        # --- ELEVATION: Spearman correlation ---\n",
    "        rho_elev, p_elev = spearmanr(group['elevation'], group['asymmetry_index'])\n",
    "        is_elev_driver = (p_elev < 0.05) and (abs(rho_elev) > 0.1)\n",
    "        \n",
    "        # --- SLOPE: Spearman correlation ---\n",
    "        rho_slope, p_slope = spearmanr(group['slope'], group['asymmetry_index'])\n",
    "        is_slope_driver = (p_slope < 0.05) and (abs(rho_slope) > 0.1)\n",
    "        \n",
    "        # --- ASPECT: Mann-Whitney with directional effect size ---\n",
    "        north = group[group['aspect'] == 1]['asymmetry_index']\n",
    "        south = group[group['aspect'] == 2]['asymmetry_index']\n",
    "        \n",
    "        if len(north) > 5 and len(south) > 5:\n",
    "            u_stat, p_aspect = mannwhitneyu(north, south)\n",
    "            \n",
    "            # Calculate effect size r = |Z| / sqrt(N)\n",
    "            n1, n2 = len(north), len(south)\n",
    "            mu = n1 * n2 / 2\n",
    "            sigma = np.sqrt(n1 * n2 * (n1 + n2 + 1) / 12)\n",
    "            z_score = (u_stat - mu) / sigma\n",
    "            r_magnitude = abs(z_score) / np.sqrt(n1 + n2)\n",
    "            \n",
    "            # Assign direction: + if North has higher asymmetry, - if South higher\n",
    "            r_aspect = r_magnitude if north.median() > south.median() else -r_magnitude\n",
    "            \n",
    "            is_aspect_driver = (p_aspect < 0.05) and (abs(r_aspect) > 0.1)\n",
    "        else:\n",
    "            r_aspect, p_aspect, is_aspect_driver = 0, 1.0, False\n",
    "        \n",
    "        # Store results\n",
    "        driver_results.append({\n",
    "            'lsp_metric': metric,\n",
    "            'ecoregion': eco_id,\n",
    "            'elev_r': round(rho_elev, 3),\n",
    "            'slope_r': round(rho_slope, 3),\n",
    "            'aspect_r': round(r_aspect, 3),\n",
    "            'elev_p': round(p_elev, 4),\n",
    "            'slope_p': round(p_slope, 4),\n",
    "            'aspect_p': round(p_aspect, 4),\n",
    "            'is_elev_driver': 'YES' if is_elev_driver else 'NO',\n",
    "            'is_slope_driver': 'YES' if is_slope_driver else 'NO',\n",
    "            'is_aspect_driver': 'YES' if is_aspect_driver else 'NO'\n",
    "        })\n",
    "    \n",
    "    # Add to overall results\n",
    "    all_driver_results.extend(driver_results)\n",
    "    \n",
    "    # Step 4: Create results table for this metric\n",
    "    drivers_df = pd.DataFrame(driver_results)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Topographic Drivers for {metric.upper()}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(\"Criteria: p < 0.05 AND |r| > 0.1\")\n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"  + value = Higher class/North aspect → more positive trends\")\n",
    "    print(\"  - value = Higher class/South aspect → more negative trends\\n\")\n",
    "    display(drivers_df)\n",
    "    \n",
    "    # Save results for this metric\n",
    "    drivers_df.to_csv(os.path.join(final_outdir, \"Topographic_Drivers.csv\"), index=False)\n",
    "\n",
    "# Save combined results for all metrics\n",
    "all_drivers_df = pd.DataFrame(all_driver_results)\n",
    "all_drivers_df.to_csv(os.path.join(output_dir, \"Topographic_Drivers_All_Metrics.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5dc54688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecoregion Summary - Trend Fit Status and Dominant Directions (Metric-wise)\n",
    "# Summarizes key statistics for each ecoregion and LSP metric combination\n",
    "\n",
    "# Initialize list to store ecoregion-metric combinations\n",
    "ecoregion_metric_summary = []\n",
    "\n",
    "for metric in lsp_metrics:\n",
    "    final_outdir = os.path.join(output_dir, f\"{metric}\")\n",
    "    \n",
    "    # Load the SU stats for this metric\n",
    "    su_stats = pd.read_csv(os.path.join(final_outdir, \"All_SU_Stats_\"+metric+\".csv\"))\n",
    "    \n",
    "    # Calculate ecoregion-level statistics for this metric\n",
    "    for eco_id in su_stats['ecoregion'].unique():\n",
    "        eco_data = su_stats[su_stats['ecoregion'] == eco_id]\n",
    "        \n",
    "        # 1. Number of SUs with at least 10 trend fitted pixels\n",
    "        n_sus = len(eco_data[eco_data['n_trend_fitted_count'] > 10])\n",
    "        \n",
    "        # 2. Percentage of pixels with fitted trend (total for ecoregion)\n",
    "        total_pixels = eco_data['n_trend_fitted_count'].sum() + eco_data['n_trend_unfitted_count'].sum()\n",
    "        fitted_pixels = eco_data['n_trend_fitted_count'].sum()\n",
    "        percent_fitted = (fitted_pixels / total_pixels * 100) if total_pixels > 0 else 0\n",
    "        \n",
    "        # 3. Percentage of pixels with significant trend from valid SUs\n",
    "        valid_sus = eco_data[eco_data['lsp_change'] == 1]\n",
    "        total_fitted = eco_data['n_trend_fitted_count'].sum()\n",
    "        sig_valid_pixels = valid_sus['n_sig_trend_count'].sum()\n",
    "        percent_sig_valid = (sig_valid_pixels / total_fitted * 100) if total_fitted > 0 else 0\n",
    "        \n",
    "        # 4. Dominant Trend Direction for this metric\n",
    "        if len(valid_sus) > 0:\n",
    "            pos_count = valid_sus['positive_sig_trend_count'].sum()\n",
    "            neg_count = valid_sus['negative_sig_trend_count'].sum()\n",
    "            asymmetry_ratio = pos_count / neg_count if neg_count > 0 else np.inf\n",
    "            \n",
    "            # Determine dominant direction based on asymmetry\n",
    "            if asymmetry_ratio > 2:  # Predominantly positive trends\n",
    "                if metric in ['sos', 'eos']:\n",
    "                    direction = 'Delay'\n",
    "                else:  # los, pos\n",
    "                    direction = 'Increasing'\n",
    "            elif asymmetry_ratio < 0.5:  # Predominantly negative trends\n",
    "                if metric in ['sos', 'eos']:\n",
    "                    direction = 'Advance'\n",
    "                else:  # los, pos\n",
    "                    direction = 'Decreasing'\n",
    "            else:  # No clear asymmetry\n",
    "                direction = 'Mixed'\n",
    "        else:\n",
    "            direction = 'No Valid SUs'\n",
    "        \n",
    "        # Store all information for this ecoregion-metric combination\n",
    "        ecoregion_metric_summary.append({\n",
    "            'lsp_metric': metric.upper(),\n",
    "            'ecoregion': eco_id,\n",
    "            'n_sus_with_min_10_fitted': n_sus,\n",
    "            'percent_fitted_pixels': round(percent_fitted, 2),\n",
    "            'percent_sig_valid_pixels': round(percent_sig_valid, 2),\n",
    "            'dominant_direction': direction\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "summary_df = pd.DataFrame(ecoregion_metric_summary)\n",
    "\n",
    "# Sort by metric and then by ecoregion\n",
    "summary_df = summary_df.sort_values(['lsp_metric', 'ecoregion']).reset_index(drop=True)\n",
    "\n",
    "#display(summary_df)\n",
    "\n",
    "# Save to CSV\n",
    "#summary_df.to_csv(r\"..\\Data\\Processed\\Trend_fit\\SummaryTrendFit.csv\", index=False)\n",
    "#print(f\"\\nSummary saved to: Data\\Processed\\Trend_fit\\SummaryTrendFit.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_stack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
